from app.models.analysis_model import *
from app.libs.kemkim import KimKem
from app.libs.progress import *
import os
import shutil
from fastapi.responses import FileResponse, JSONResponse
from starlette.background import BackgroundTask
from kiwipiepy import Kiwi
import time
import pandas as pd
import re
from kiwipiepy import Kiwi
import torch, numpy as np
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TextClassificationPipeline,
)
import os
from dotenv import load_dotenv

load_dotenv() 

MODEL_DIR = os.getenv("MODEL_PATH")  # .env íŒŒì¼ì—ì„œ ì½ê¸°

tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, local_files_only=True)
model     = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR, local_files_only=True)
pipe = TextClassificationPipeline(
    model=model,
    tokenizer=tokenizer,
    function_to_apply="sigmoid",
    top_k=None,                                # ì „ì²´ ë ˆì´ë¸” í™•ë¥  ë°˜í™˜
    device=0 if torch.cuda.is_available() else -1,
)

# clean ì œì™¸í•œ 8ê°œ í˜ì˜¤Â·ì•…í”Œ ë ˆì´ë¸”
hate_labels = [lbl for lbl in model.config.id2label.values() if lbl != "clean"]


def start_kemkim(option: KemKimOption, token_data):

    def cleanup_folder_and_zip(folder_path: str, zip_path: str):
        # í´ë”ì™€ ZIP íŒŒì¼ì„ ì‚­ì œ
        shutil.rmtree(folder_path, ignore_errors=True)
        try:
            os.remove(zip_path)
        except OSError:
            pass

    option = option.model_dump()
    save_path = os.path.join(os.path.dirname(__file__), '..', 'temp')

    kemkim_obj = KimKem(
        pid=option["pid"],
        token_data=token_data,
        csv_name=option["tokenfile_name"],
        save_path=save_path,
        startdate=option["startdate"],
        enddate=option["enddate"],
        period=option["period"],
        topword=option["topword"],
        weight=option["weight"],
        graph_wordcnt=option["graph_wordcnt"],
        split_option=option["split_option"],
        split_custom=option["split_custom"],
        filter_option=option["filter_option"],
        trace_standard=option["trace_standard"],
        ani_option=option["ani_option"],
        exception_word_list=option["exception_word_list"],
        exception_filename=option["exception_filename"],
        modify_kemkim=False
    )
    try:
        result_path = kemkim_obj.make_kimkem()

        if type(result_path) == str:
            zip_path = shutil.make_archive(
                result_path, "zip", root_dir=result_path)
            filename = os.path.basename(zip_path)  # ì—¬ê¸°ì— í•œê¸€ì´ ì„ì—¬ ìˆì–´ë„ OK

            background_task = BackgroundTask(
                cleanup_folder_and_zip, result_path, zip_path)

            # 4) FileResponseì— filename= ìœ¼ë¡œ ë„˜ê¸°ê¸°
            return FileResponse(
                path=zip_path,
                media_type="application/zip",
                filename=filename,
                background=background_task,
            )
        elif result_path == 2:
            # â—ì˜ˆì™¸ ìƒí™© ë©”ì‹œì§€ ì‘ë‹µ
            return JSONResponse(
                status_code=400,
                content={"error": "KEMKIM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                         "message": "ì‹œê°„ ê°€ì¤‘ì¹˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"}
            )
        elif result_path == 3:
            # â—ì˜ˆì™¸ ìƒí™© ë©”ì‹œì§€ ì‘ë‹µ
            return JSONResponse(
                status_code=400,
                content={"error": "KEMKIM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                         "message": "í‚¤ì›Œë“œê°€ ì—†ì–´ ë¶„ì„ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"}
            )

    except Exception as e:
        # â—ì˜ˆì™¸ ìƒí™© ë©”ì‹œì§€ ì‘ë‹µ
        return JSONResponse(
            status_code=500,
            content={"error": "KEMKIM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "message": str(e)}
        )

def tokenization(
    pid: str,
    data: pd.DataFrame,
    columns,
    include_words: list = None,
    update_interval: int = 3000,
) -> pd.DataFrame:
    """
    â–¸ pid            : ì§„í–‰ ìƒí™©ì„ send_message(pid, â€¦)ë¡œ ì „ë‹¬í•  ë•Œ ì‚¬ìš©
    â–¸ data           : ì›ë³¸ DataFrame (in-place ìˆ˜ì •)
    â–¸ columns        : í† í°í™”í•  ì—´ ì´ë¦„ ë˜ëŠ” ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    â–¸ update_interval: ì´ ê°œìˆ˜ë§ˆë‹¤ ì§„í–‰ë¥  ë©”ì‹œì§€ ì „ì†¡
    """
    # 1) Kiwi í•œ ë²ˆë§Œ ì´ˆê¸°í™”
    kiwi = Kiwi(num_workers=-1)
    for word in include_words:
        kiwi.add_user_word(word, 'NNP', score=10)

    # 2) ë‹¨ì¼ str â†’ list
    if isinstance(columns, str):
        columns = [columns]

    # 3) ê° ì—´ì„ ìˆœíšŒ
    for col in columns:
        if col not in data.columns:
            send_message(pid, f"âš ï¸  ì—´ '{col}'ì´(ê°€) ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ â†’ ê±´ë„ˆëœ€")
            continue

        texts        = data[col].tolist()
        total        = len(texts)
        tokenized_col = []

        send_message(pid, f"[{col}] í† í°í™” ì‹œì‘ (ì´ {total:,} rows)")

        total_time = 0.0
        for idx, text in enumerate(texts, 1):
            start = time.time()

            if isinstance(text, str):
                # ì „ì²˜ë¦¬
                cleaned = re.sub(r"[^ê°€-í£a-zA-Z\s]", "", text)
                # splitComplex=False â†’ ë³µí•©ì–´ë¥¼ ë¶„í•´í•˜ì§€ ì•Šê³  ì²˜ë¦¬
                tokens   = kiwi.tokenize(cleaned, split_complex=False)
                nouns    = [t.form for t in tokens if t.tag in ("NNG", "NNP")]
                tokenized_col.append(", ".join(nouns))
            else:
                tokenized_col.append("")

            # ì§„í–‰ë¥  ê³„ì‚°
            total_time += time.time() - start
            if idx % update_interval == 0 or idx == total:
                pct   = round(idx / total * 100, 2)
                avg   = total_time / idx
                remain_sec = avg * (total - idx)
                m, s  = divmod(int(remain_sec), 60)
                send_message(
                    pid,
                    f"[{col}] ì§„í–‰ë¥  {pct}% ({idx:,}/{total:,}) â€¢ ì˜ˆìƒ ë‚¨ì€ ì‹œê°„ {m}ë¶„ {s}ì´ˆ"
                )

        # ì—´ ë®ì–´ì“°ê¸°
        data[col] = tokenized_col
        send_message(pid, f"[{col}] í† í°í™” ì™„ë£Œ âœ…")

    return data

def measure_hate(
    option: HateOption,
    data: pd.DataFrame,
    text_col: str | None = "Text",
    update_interval: int = 1000,
) -> pd.DataFrame:
    """
    â–¸ option.option_num
        1 â†’ clean ì œì™¸ ë ˆì´ë¸” ì¤‘ ìµœëŒ€ê°’ â†’ 'Hate'  ì—´
        2 â†’ clean í™•ë¥                â†’ 'Clean' ì—´
        3 â†’ 10ê°œ ë ˆì´ë¸” ëª¨ë‘         â†’ ê° ë ˆì´ë¸”ëª…ì´ ì—´
    â–¸ text_colì´ DataFrameì— ì—†ìœ¼ë©´
        ì´ë¦„ì— 'text'ê°€ í¬í•¨ëœ ì²« ë²ˆì§¸ ì—´ì„ ìë™ ì„ íƒ
    """
    
    def measure_hatefulness(text: str) -> dict[str, float]:
        """
        í•œêµ­ì–´ ë¬¸ì¥ì˜ í˜ì˜¤ë„ í™•ë¥ (0~1)ì„ ì†Œìˆ˜ ë‘˜ì§¸ ìë¦¬ê¹Œì§€ ë°˜ì˜¬ë¦¼í•´ ë°˜í™˜
        """
        outputs = pipe(text, truncation=True)[0]          # [{'label':â€¦, 'score':â€¦}, â€¦]
        # â†â˜… ì—¬ê¸°ì„œ ë°”ë¡œ ë°˜ì˜¬ë¦¼
        scores  = {o["label"]: round(o["score"], 2) for o in outputs}
        return scores
    
    pid  = option.pid
    mode = option.option_num

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # â‘  ë¶„ì„ ëŒ€ìƒ ì—´(auto-detect)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if text_col not in data.columns:
        # 'text' í¬í•¨ ì—´ ìë™ ê²€ìƒ‰ (ëŒ€ì†Œë¬¸ì ë¬´ê´€)
        candidates = [c for c in data.columns if "text" in c.lower()]
        if not candidates:
            raise ValueError(
                "'Text'ë¼ëŠ” ê¸€ìë¥¼ í¬í•¨í•œ ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ "
                "(text_col ì¸ìë¡œ ì§ì ‘ ì§€ì •í•´ ì£¼ì„¸ìš”)."
            )
        text_col = candidates[0]
        send_message(pid, f"ğŸ” '{text_col}' ì—´ì„ ìë™ìœ¼ë¡œ ì„ íƒí–ˆìŠµë‹ˆë‹¤")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # â‘¡ ê²°ê³¼ ë²„í¼ ì¤€ë¹„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if mode == 1:
        hate_vals = []
    elif mode == 2:
        clean_vals = []
    elif mode == 3:
        all_labels  = list(model.config.id2label.values())   # 10ê°œ
        scores_dict = {lbl: [] for lbl in all_labels}
    else:
        raise ValueError("option_num must be 1, 2, ë˜ëŠ” 3 ì´ì–´ì•¼ í•©ë‹ˆë‹¤")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # â‘¢ row ë‹¨ìœ„ ì²˜ë¦¬
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    total = len(data)
    send_message(pid, f"[í˜ì˜¤ë„ ë¶„ì„] '{text_col}' ì—´ ì²˜ë¦¬ ì‹œì‘ (ì´ {total:,} rows)")

    for idx, text in enumerate(data[text_col], 1):
        # ë¹ˆ ì¹¸âˆ™NaN ë°©ì–´
        if isinstance(text, str) and text.strip():
            scores = measure_hatefulness(text)      # dict(label â†’ prob 0~1)
        else:
            scores = {lbl: 0.0 for lbl in model.config.id2label.values()}

        if mode == 1:
            hate_vals.append(max(v for k, v in scores.items() if k != "clean"))
        elif mode == 2:
            clean_vals.append(scores.get("clean", 0.0))
        else:   # mode == 3
            for lbl in scores_dict:
                scores_dict[lbl].append(scores.get(lbl, 0.0))

        # ì§„í–‰ë¥  ë©”ì‹œì§€
        if idx % update_interval == 0 or idx == total:
            pct = round(idx / total * 100, 2)
            send_message(pid, f"[í˜ì˜¤ë„ ë¶„ì„] {pct}% ì™„ë£Œ ({idx:,}/{total:,})")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # â‘£ DataFrame ì—´ ì¶”ê°€
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if mode == 1:
        data["Hate"] = hate_vals
    elif mode == 2:
        data["Clean"] = clean_vals
    else:  # mode == 3
        for lbl, vals in scores_dict.items():
            data[lbl] = vals

    send_message(pid, "[í˜ì˜¤ë„ ë¶„ì„] ì™„ë£Œ âœ…")
    return data
