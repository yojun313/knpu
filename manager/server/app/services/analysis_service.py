from app.models.analysis_model import *
from app.libs.kemkim import KimKem
from app.libs.progress import *
import os
import shutil
from fastapi.responses import FileResponse, JSONResponse
from starlette.background import BackgroundTask
from kiwipiepy import Kiwi
import time
import pandas as pd
import re
from kiwipiepy import Kiwi
import torch, numpy as np
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TextClassificationPipeline,
)
import os
from dotenv import load_dotenv

load_dotenv() 

MODEL_DIR = os.getenv("MODEL_PATH")  # .env íŒŒì¼ì—ì„œ ì½ê¸°

tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, local_files_only=True)
model     = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR, local_files_only=True)
pipe = TextClassificationPipeline(
    model=model,
    tokenizer=tokenizer,
    function_to_apply="sigmoid",
    top_k=None,                                # ì „ì²´ ë ˆì´ë¸” í™•ë¥  ë°˜í™˜
    device=0 if torch.cuda.is_available() else -1,
)

# clean ì œì™¸í•œ 8ê°œ í˜ì˜¤Â·ì•…í”Œ ë ˆì´ë¸”
hate_labels = [lbl for lbl in model.config.id2label.values() if lbl != "clean"]


def start_kemkim(option: KemKimOption, token_data):

    def cleanup_folder_and_zip(folder_path: str, zip_path: str):
        # í´ë”ì™€ ZIP íŒŒì¼ì„ ì‚­ì œ
        shutil.rmtree(folder_path, ignore_errors=True)
        try:
            os.remove(zip_path)
        except OSError:
            pass

    option = option.model_dump()
    save_path = os.path.join(os.path.dirname(__file__), '..', 'temp')

    kemkim_obj = KimKem(
        pid=option["pid"],
        token_data=token_data,
        csv_name=option["tokenfile_name"],
        save_path=save_path,
        startdate=option["startdate"],
        enddate=option["enddate"],
        period=option["period"],
        topword=option["topword"],
        weight=option["weight"],
        graph_wordcnt=option["graph_wordcnt"],
        split_option=option["split_option"],
        split_custom=option["split_custom"],
        filter_option=option["filter_option"],
        trace_standard=option["trace_standard"],
        ani_option=option["ani_option"],
        exception_word_list=option["exception_word_list"],
        exception_filename=option["exception_filename"],
        modify_kemkim=False
    )
    try:
        result_path = kemkim_obj.make_kimkem()

        if type(result_path) == str:
            zip_path = shutil.make_archive(
                result_path, "zip", root_dir=result_path)
            filename = os.path.basename(zip_path)  # ì—¬ê¸°ì— í•œê¸€ì´ ì„ì—¬ ìˆì–´ë„ OK

            background_task = BackgroundTask(
                cleanup_folder_and_zip, result_path, zip_path)

            # 4) FileResponseì— filename= ìœ¼ë¡œ ë„˜ê¸°ê¸°
            return FileResponse(
                path=zip_path,
                media_type="application/zip",
                filename=filename,
                background=background_task,
            )
        elif result_path == 2:
            # â—ì˜ˆì™¸ ìƒí™© ë©”ì‹œì§€ ì‘ë‹µ
            return JSONResponse(
                status_code=400,
                content={"error": "KEMKIM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                         "message": "ì‹œê°„ ê°€ì¤‘ì¹˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"}
            )
        elif result_path == 3:
            # â—ì˜ˆì™¸ ìƒí™© ë©”ì‹œì§€ ì‘ë‹µ
            return JSONResponse(
                status_code=400,
                content={"error": "KEMKIM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                         "message": "í‚¤ì›Œë“œê°€ ì—†ì–´ ë¶„ì„ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"}
            )

    except Exception as e:
        # â—ì˜ˆì™¸ ìƒí™© ë©”ì‹œì§€ ì‘ë‹µ
        return JSONResponse(
            status_code=500,
            content={"error": "KEMKIM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "message": str(e)}
        )

def tokenization(
    pid: str,
    data: pd.DataFrame,
    columns,
    include_words: list = None,
    update_interval: int = 3000,
) -> pd.DataFrame:
    """
    â–¸ pid            : ì§„í–‰ ìƒí™©ì„ send_message(pid, â€¦)ë¡œ ì „ë‹¬í•  ë•Œ ì‚¬ìš©
    â–¸ data           : ì›ë³¸ DataFrame (in-place ìˆ˜ì •)
    â–¸ columns        : í† í°í™”í•  ì—´ ì´ë¦„ ë˜ëŠ” ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    â–¸ update_interval: ì´ ê°œìˆ˜ë§ˆë‹¤ ì§„í–‰ë¥  ë©”ì‹œì§€ ì „ì†¡
    """
    # 1) Kiwi í•œ ë²ˆë§Œ ì´ˆê¸°í™”
    kiwi = Kiwi(num_workers=-1)
    for word in include_words:
        kiwi.add_user_word(word, 'NNP', score=10)

    # 2) ë‹¨ì¼ str â†’ list
    if isinstance(columns, str):
        columns = [columns]

    # 3) ê° ì—´ì„ ìˆœíšŒ
    for col in columns:
        if col not in data.columns:
            send_message(pid, f"âš ï¸  ì—´ '{col}'ì´(ê°€) ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ â†’ ê±´ë„ˆëœ€")
            continue

        texts        = data[col].tolist()
        total        = len(texts)
        tokenized_col = []

        send_message(pid, f"[{col}] í† í°í™” ì‹œì‘ (ì´ {total:,} rows)")

        total_time = 0.0
        for idx, text in enumerate(texts, 1):
            start = time.time()

            if isinstance(text, str):
                # ì „ì²˜ë¦¬
                cleaned = re.sub(r"[^ê°€-í£a-zA-Z\s]", "", text)
                # splitComplex=False â†’ ë³µí•©ì–´ë¥¼ ë¶„í•´í•˜ì§€ ì•Šê³  ì²˜ë¦¬
                tokens   = kiwi.tokenize(cleaned, split_complex=False)
                nouns    = [t.form for t in tokens if t.tag in ("NNG", "NNP")]
                tokenized_col.append(", ".join(nouns))
            else:
                tokenized_col.append("")

            # ì§„í–‰ë¥  ê³„ì‚°
            total_time += time.time() - start
            if idx % update_interval == 0 or idx == total:
                pct   = round(idx / total * 100, 2)
                avg   = total_time / idx
                remain_sec = avg * (total - idx)
                m, s  = divmod(int(remain_sec), 60)
                send_message(
                    pid,
                    f"[{col}] ì§„í–‰ë¥  {pct}% ({idx:,}/{total:,}) â€¢ ì˜ˆìƒ ë‚¨ì€ ì‹œê°„ {m}ë¶„ {s}ì´ˆ"
                )

        # ì—´ ë®ì–´ì“°ê¸°
        data[col] = tokenized_col
        send_message(pid, f"[{col}] í† í°í™” ì™„ë£Œ âœ…")

    return data

def measure_hate(
    option: HateOption,
    data: pd.DataFrame,
    text_col: str | None = "Text",
    update_interval: int = 1000,
    batch_size: int = 32,           # â† ì¶”ê°€: ë°°ì¹˜ í¬ê¸°
) -> pd.DataFrame:
    """
    ì˜µì…˜ 1: Hate  / 2: Clean  / 3: ëª¨ë“  ë ˆì´ë¸”
    í™•ë¥ ì€ ì†Œìˆ˜ ë‘˜ì§¸ ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼
    """

    # â”€â”€â”€â”€â”€ ë‚´ë¶€ í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def outputs_to_scores(outputs):
        """ pipeline ì¶œë ¥(list[dict]) â†’ {label: rounded_prob} """
        return {o["label"]: round(o["score"], 2) for o in outputs}
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    pid, mode = option.pid, option.option_num

    # â‘  ëŒ€ìƒ ì—´ í™•ì¸ / ìë™ íƒìƒ‰
    if text_col not in data.columns:
        cand = [c for c in data.columns if "text" in c.lower()]
        if not cand:
            raise ValueError("'Text' í¬í•¨ ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        text_col = cand[0]
        send_message(pid, f"ğŸ” '{text_col}' ì—´ì„ ìë™ ì„ íƒí–ˆìŠµë‹ˆë‹¤")

    total = len(data)
    send_message(pid, f"[í˜ì˜¤ë„ ë¶„ì„] '{text_col}' ì²˜ë¦¬ ì‹œì‘ (ì´ {total:,} rows)")

    # â‘¡ ê²°ê³¼ ë²„í¼ ì´ˆê¸°í™”
    all_labels = list(model.config.id2label.values())
    if mode == 1:
        hate_vals = [0.0] * total
    elif mode == 2:
        clean_vals = [0.0] * total
    else:  # mode == 3
        scores_dict = {lbl: [0.0] * total for lbl in all_labels}

    # â‘¢ ë°°ì¹˜ ì²˜ë¦¬
    texts = data[text_col].fillna("").tolist()
    processed = 0

    for start in range(0, total, batch_size):
        end = min(start + batch_size, total)

        # ë¹„ì–´ ìˆì§€ ì•Šì€ í–‰ë§Œ ì¶”ë ¤ì„œ ì¶”ë¡ 
        idxs, batch_txts = [], []
        for i in range(start, end):
            t = texts[i]
            if isinstance(t, str) and t.strip():
                idxs.append(i)
                batch_txts.append(t)

        if batch_txts:
            batch_outputs = pipe(
                batch_txts,
                truncation=True,
                batch_size=batch_size,
            )
            for i, outs in zip(idxs, batch_outputs):
                scores = outputs_to_scores(outs)
                if mode == 1:
                    hate_vals[i] = max(v for k, v in scores.items() if k != "clean")
                elif mode == 2:
                    clean_vals[i] = scores.get("clean", 0.0)
                else:  # mode == 3
                    for lbl in scores_dict:
                        scores_dict[lbl][i] = scores.get(lbl, 0.0)

        processed += (end - start)
        if processed % update_interval == 0 or processed == total:
            pct = round(processed / total * 100, 2)
            send_message(pid, f"[í˜ì˜¤ë„ ë¶„ì„] {pct}% ì™„ë£Œ ({processed:,}/{total:,})")

    # â‘£ ê²°ê³¼ ì—´ ì¶”ê°€
    if mode == 1:
        data["Hate"] = hate_vals
    elif mode == 2:
        data["Clean"] = clean_vals
    else:
        for lbl, vals in scores_dict.items():
            data[lbl] = vals

    send_message(pid, "[í˜ì˜¤ë„ ë¶„ì„] ì™„ë£Œ âœ…")
    return data
