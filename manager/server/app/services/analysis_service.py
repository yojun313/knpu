from app.models.analysis_model import *
from app.libs.kemkim import KimKem
from app.libs.progress import *
import os
import shutil
from fastapi.responses import FileResponse, JSONResponse
from starlette.background import BackgroundTask
from kiwipiepy import Kiwi
import time
import pandas as pd
import re
from kiwipiepy import Kiwi
import torch, numpy as np
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TextClassificationPipeline,
)
import os
from dotenv import load_dotenv

load_dotenv() 

MODEL_DIR = os.getenv("MODEL_PATH")  # .env íŒŒì¼ì—ì„œ ì½ê¸°

tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, local_files_only=True)
model     = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR, local_files_only=True)
pipe = TextClassificationPipeline(
    model=model,
    tokenizer=tokenizer,
    function_to_apply="sigmoid",
    top_k=None,                                # ì „ì²´ ë ˆì´ë¸” í™•ë¥  ë°˜í™˜
    device=0 if torch.cuda.is_available() else -1,
)

# clean ì œì™¸í•œ 8ê°œ í˜ì˜¤Â·ì•…í”Œ ë ˆì´ë¸”
hate_labels = [lbl for lbl in model.config.id2label.values() if lbl != "clean"]


def start_kemkim(option: KemKimOption, token_data):

    def cleanup_folder_and_zip(folder_path: str, zip_path: str):
        # í´ë”ì™€ ZIP íŒŒì¼ì„ ì‚­ì œ
        shutil.rmtree(folder_path, ignore_errors=True)
        try:
            os.remove(zip_path)
        except OSError:
            pass

    option = option.model_dump()
    save_path = os.path.join(os.path.dirname(__file__), '..', 'temp')

    kemkim_obj = KimKem(
        pid=option["pid"],
        token_data=token_data,
        csv_name=option["tokenfile_name"],
        save_path=save_path,
        startdate=option["startdate"],
        enddate=option["enddate"],
        period=option["period"],
        topword=option["topword"],
        weight=option["weight"],
        graph_wordcnt=option["graph_wordcnt"],
        split_option=option["split_option"],
        split_custom=option["split_custom"],
        filter_option=option["filter_option"],
        trace_standard=option["trace_standard"],
        ani_option=option["ani_option"],
        exception_word_list=option["exception_word_list"],
        exception_filename=option["exception_filename"],
        modify_kemkim=False
    )
    try:
        result_path = kemkim_obj.make_kimkem()

        if type(result_path) == str:
            zip_path = shutil.make_archive(
                result_path, "zip", root_dir=result_path)
            filename = os.path.basename(zip_path)  # ì—¬ê¸°ì— í•œê¸€ì´ ì„ì—¬ ìˆì–´ë„ OK

            background_task = BackgroundTask(
                cleanup_folder_and_zip, result_path, zip_path)

            # 4) FileResponseì— filename= ìœ¼ë¡œ ë„˜ê¸°ê¸°
            return FileResponse(
                path=zip_path,
                media_type="application/zip",
                filename=filename,
                background=background_task,
            )
        elif result_path == 2:
            # â—ì˜ˆì™¸ ìƒí™© ë©”ì‹œì§€ ì‘ë‹µ
            return JSONResponse(
                status_code=400,
                content={"error": "KEMKIM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                         "message": "ì‹œê°„ ê°€ì¤‘ì¹˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"}
            )
        elif result_path == 3:
            # â—ì˜ˆì™¸ ìƒí™© ë©”ì‹œì§€ ì‘ë‹µ
            return JSONResponse(
                status_code=400,
                content={"error": "KEMKIM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                         "message": "í‚¤ì›Œë“œê°€ ì—†ì–´ ë¶„ì„ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"}
            )

    except Exception as e:
        # â—ì˜ˆì™¸ ìƒí™© ë©”ì‹œì§€ ì‘ë‹µ
        return JSONResponse(
            status_code=500,
            content={"error": "KEMKIM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", "message": str(e)}
        )

def tokenization(
    pid: str,
    data: pd.DataFrame,
    columns,
    include_words: list = None,
    update_interval: int = 3000,
) -> pd.DataFrame:
    """
    â–¸ pid            : ì§„í–‰ ìƒí™©ì„ send_message(pid, â€¦)ë¡œ ì „ë‹¬í•  ë•Œ ì‚¬ìš©
    â–¸ data           : ì›ë³¸ DataFrame (in-place ìˆ˜ì •)
    â–¸ columns        : í† í°í™”í•  ì—´ ì´ë¦„ ë˜ëŠ” ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    â–¸ update_interval: ì´ ê°œìˆ˜ë§ˆë‹¤ ì§„í–‰ë¥  ë©”ì‹œì§€ ì „ì†¡
    """
    # 1) Kiwi í•œ ë²ˆë§Œ ì´ˆê¸°í™”
    kiwi = Kiwi(num_workers=-1)
    for word in include_words:
        kiwi.add_user_word(word, 'NNP', score=10)

    # 2) ë‹¨ì¼ str â†’ list
    if isinstance(columns, str):
        columns = [columns]

    # 3) ê° ì—´ì„ ìˆœíšŒ
    for col in columns:
        if col not in data.columns:
            send_message(pid, f"âš ï¸  ì—´ '{col}'ì´(ê°€) ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ â†’ ê±´ë„ˆëœ€")
            continue

        texts        = data[col].tolist()
        total        = len(texts)
        tokenized_col = []

        send_message(pid, f"[{col}] í† í°í™” ì‹œì‘ (ì´ {total:,} rows)")

        total_time = 0.0
        for idx, text in enumerate(texts, 1):
            start = time.time()

            if isinstance(text, str):
                # ì „ì²˜ë¦¬
                cleaned = re.sub(r"[^ê°€-í£a-zA-Z\s]", "", text)
                # splitComplex=False â†’ ë³µí•©ì–´ë¥¼ ë¶„í•´í•˜ì§€ ì•Šê³  ì²˜ë¦¬
                tokens   = kiwi.tokenize(cleaned, split_complex=False)
                nouns    = [t.form for t in tokens if t.tag in ("NNG", "NNP")]
                tokenized_col.append(", ".join(nouns))
            else:
                tokenized_col.append("")

            # ì§„í–‰ë¥  ê³„ì‚°
            total_time += time.time() - start
            if idx % update_interval == 0 or idx == total:
                pct   = round(idx / total * 100, 2)
                avg   = total_time / idx
                remain_sec = avg * (total - idx)
                m, s  = divmod(int(remain_sec), 60)
                send_message(
                    pid,
                    f"[{col}] ì§„í–‰ë¥  {pct}% ({idx:,}/{total:,}) â€¢ ì˜ˆìƒ ë‚¨ì€ ì‹œê°„ {m}ë¶„ {s}ì´ˆ"
                )

        # ì—´ ë®ì–´ì“°ê¸°
        data[col] = tokenized_col
        send_message(pid, f"[{col}] í† í°í™” ì™„ë£Œ âœ…")

    return data

def measure_hate(
    option: HateOption,
    data: pd.DataFrame,
    text_col: str | None = "Text",
    update_interval: int = 1_000,
    batch_size: int = 32,           # â† ë°°ì¹˜ í¬ê¸°(ë©”ëª¨ë¦¬ì— ë§ê²Œ 16~64 ì¡°ì •)
) -> pd.DataFrame:
    """
    option.option_num
      1 â†’ clean ì œì™¸ ë ˆì´ë¸” ì¤‘ ìµœëŒ€ê°’ â†’ Hate ì—´
      2 â†’ 10ê°œ ë ˆì´ë¸” ëª¨ë‘         â†’ ë ˆì´ë¸”ëª…ë³„ ì—´
      3 â†’ clean í™•ë¥                â†’ Clean ì—´

    â€¢ í™•ë¥ ì€ ì†Œìˆ˜ ë‘˜ì§¸ ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼
    â€¢ ë°°ì¹˜ ì¶”ë¡ ìœ¼ë¡œ ì†ë„ í–¥ìƒ
    """

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë‚´ë¶€ í—¬í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def batch_scores(texts: list[str]) -> list[dict[str, float]]:
        """ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ â†’ [{label: prob}, ...] (ë‘˜ì§¸ ìë¦¬ ë°˜ì˜¬ë¦¼)"""
        outs = pipe(
            texts,
            truncation=True,
            batch_size=batch_size,
        )
        return [{o["label"]: round(o["score"], 2) for o in each} for each in outs]
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    pid, mode = option.pid, option.option_num

    # â‘  ëŒ€ìƒ ì—´ íƒìƒ‰ -----------------------------------------------------------
    if text_col not in data.columns:
        matches = [c for c in data.columns if "text" in c.lower()]
        if not matches:
            raise ValueError("'Text'ë¼ëŠ” ê¸€ìë¥¼ í¬í•¨í•œ ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        text_col = matches[0]
        send_message(pid, f"ğŸ” '{text_col}' ì—´ ìë™ ì„ íƒ")

    texts  = data[text_col].fillna("").astype(str).tolist()
    total  = len(texts)
    labels = list(model.config.id2label.values())

    send_message(pid, f"[í˜ì˜¤ë„ ë¶„ì„] '{text_col}' ì²˜ë¦¬ ì‹œì‘ (ì´ {total:,} rows)")

    # â‘¡ ê²°ê³¼ ë²„í¼ --------------------------------------------------------------
    if mode == 1:                              # Hate
        hate_vals = [0.0] * total
    elif mode == 2:                            # ì „ì²´ ë ˆì´ë¸”
        scores_dict = {lbl: [0.0] * total for lbl in labels}
    elif mode == 3:                            # Clean
        clean_vals = [0.0] * total
    else:
        raise ValueError("option_num must be 1, 2, ë˜ëŠ” 3 ì´ì–´ì•¼ í•©ë‹ˆë‹¤")

    # â‘¢ ë°°ì¹˜ ì¶”ë¡  --------------------------------------------------------------
    processed = 0
    for start in range(0, total, batch_size):
        end = min(start + batch_size, total)

        # ì‹¤ì œ ì¶”ë¡ ì´ í•„ìš”í•œ ë¬¸ì¥ ì¸ë±ìŠ¤ & í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        idxs, batch_txts = [], []
        for i in range(start, end):
            t = texts[i].strip()
            if t:                               # ê³µë°±ì€ ì¶”ë¡  ê±´ë„ˆëœ€
                idxs.append(i)
                batch_txts.append(t)

        if batch_txts:
            scored = batch_scores(batch_txts)   # ëª¨ë¸ í•œë²ˆ í˜¸ì¶œ
            for i, sc in zip(idxs, scored):
                if mode == 1:
                    hate_vals[i] = max(v for k, v in sc.items() if k != "clean")
                elif mode == 2:
                    for lbl in labels:
                        scores_dict[lbl][i] = sc.get(lbl, 0.0)
                else:  # mode == 3
                    clean_vals[i] = sc.get("clean", 0.0)

        processed += (end - start)
        if processed % update_interval == 0 or processed == total:
            pct = round(processed / total * 100, 2)
            send_message(pid, f"[í˜ì˜¤ë„ ë¶„ì„] {pct}% ì™„ë£Œ ({processed:,}/{total:,})")

    # â‘£ ê²°ê³¼ ì—´ ë¶™ì´ê¸° -----------------------------------------------------------
    if mode == 1:
        data["Hate"] = hate_vals
    elif mode == 2:
        for lbl, vals in scores_dict.items():
            data[lbl] = vals
    else:  # mode == 3
        data["Clean"] = clean_vals

    send_message(pid, "[í˜ì˜¤ë„ ë¶„ì„] ì™„ë£Œ âœ…")
    return data

