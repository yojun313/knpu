from app.models.analysis_model import *
from app.libs.progress import *
import os
os.environ["TRANSFORMERS_VERBOSITY"] = "error"
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
import pandas as pd
import torch
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TextClassificationPipeline,
    logging
)
logging.set_verbosity_error()
import os
from dotenv import load_dotenv
import gc

load_dotenv() 

kor_unsmile_pipe = None

def get_hate_model():
    global kor_unsmile_pipe
    MODEL_DIR = os.getenv("MODEL_PATH")
    
    if kor_unsmile_pipe is None:
        tokenizer = AutoTokenizer.from_pretrained(os.path.join(MODEL_DIR, "kor_unsmile"), local_files_only=True)
        kor_unsmile_model = AutoModelForSequenceClassification.from_pretrained(os.path.join(MODEL_DIR, "kor_unsmile"), local_files_only=True)
        kor_unsmile_pipe = TextClassificationPipeline(
            model=kor_unsmile_model,
            tokenizer=tokenizer,
            function_to_apply="sigmoid",
            top_k=None,
            device=1 if torch.cuda.is_available() else -1,
        )

    return kor_unsmile_pipe

def unload_hate_model():
    global kor_unsmile_pipe
    kor_unsmile_pipe = None
    torch.cuda.empty_cache()
    gc.collect()

def measure_hate(
    option: HateOption,
    data: pd.DataFrame,
    text_col: str | None = "Text",
    update_interval: int = 1_000,
    batch_size: int = 256,
) -> pd.DataFrame:
    """
    option.option_num
      1 â†’ clean ì œì™¸ ë ˆì´ë¸” ì¤‘ ìµœëŒ€ê°’ â†’ Hate ì—´
      2 â†’ 10ê°œ ë ˆì´ë¸” ëª¨ë‘         â†’ ë ˆì´ë¸”ëª…ë³„ ì—´
      3 â†’ clean í™•ë¥                â†’ Clean ì—´
    """

    def batch_scores(texts: list[str]) -> list[dict[str, float]]:
        """ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ â†’ [{label: prob}, ...] (ë‘˜ì§¸ ìë¦¬ ë°˜ì˜¬ë¦¼)"""
        pipe = get_hate_model()
        outs = pipe(
            texts,
            truncation=True,
            batch_size=batch_size,
        )
        return [
            {o["label"]: round(o["score"], 2) for o in each}
            for each in outs
        ]


    pid, mode = option.pid, option.option_num

    # ëŒ€ìƒ ì—´ íƒìƒ‰ 
    if text_col not in data.columns:
        for c in data.columns:
            if "text" in c.lower():
                text_col = c
                send_message(pid, f"ğŸ” '{text_col}' ì—´ ìë™ ì„ íƒ")
                break
        else:
            raise ValueError("'Text'ë¼ëŠ” ê¸€ìë¥¼ í¬í•¨í•œ ì—´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    texts = data[text_col].fillna("").astype(str).tolist()
    total = len(texts)
    pipe = get_hate_model()
    labels = list(pipe.model.config.id2label.values())
    
    send_message(pid, f"[í˜ì˜¤ë„ ë¶„ì„] '{text_col}' ì²˜ë¦¬ ì‹œì‘ (ì´ {total:,} rows)")

    # ê²°ê³¼ ë²„í¼ 
    if mode == 1:
        results = [0.0] * total
    elif mode == 2:
        # dict ëŒ€ì‹  numpy arrayë¥¼ ì“°ëŠ” ê²ƒë„ ì„±ëŠ¥ í–¥ìƒì— ì¢‹ìŒ
        results = {lbl: [0.0] * total for lbl in labels}
    elif mode == 3:
        results = [0.0] * total
    else:
        raise ValueError("option_num must be 1, 2, ë˜ëŠ” 3 ì´ì–´ì•¼ í•©ë‹ˆë‹¤")

    # ë¯¸ë¦¬ ë¹„ì–´ìˆì§€ ì•Šì€ ì¸ë±ìŠ¤ í•„í„°ë§ 
    non_empty_indices = [i for i, t in enumerate(texts) if t.strip()]
    non_empty_texts = [texts[i].strip() for i in non_empty_indices]
    total_non_empty = len(non_empty_indices)

    # ë°°ì¹˜ ì¶”ë¡  
    for batch_start in range(0, total_non_empty, batch_size):
        batch_end = min(batch_start + batch_size, total_non_empty)
        batch_idx = non_empty_indices[batch_start:batch_end]
        batch_txt = non_empty_texts[batch_start:batch_end]

        # ëª¨ë¸ í•œ ë²ˆ í˜¸ì¶œ
        scored = batch_scores(batch_txt)

        # ê²°ê³¼ ì±„ìš°ê¸°
        if mode == 1:
            for idx, sc in zip(batch_idx, scored):
                results[idx] = max(v for k, v in sc.items() if k != "clean")
        elif mode == 2:
            for idx, sc in zip(batch_idx, scored):
                for lbl in labels:
                    results[lbl][idx] = sc.get(lbl, 0.0)
        else:  # mode == 3
            for idx, sc in zip(batch_idx, scored):
                results[idx] = sc.get("clean", 0.0)

        if (batch_end % update_interval == 0) or (batch_end == total_non_empty):
            pct = round(batch_end / total_non_empty * 100, 2)
            send_message(pid, f"[í˜ì˜¤ë„ ë¶„ì„] {pct}% ì™„ë£Œ ({batch_end:,}/{total_non_empty:,})")

    # ê²°ê³¼ ì—´ ë¶™ì´ê¸°
    if mode == 1:
        data["Hate"] = results
    elif mode == 2:
        for lbl, vals in results.items():
            data[lbl] = vals
    else:
        data["Clean"] = results

    send_message(pid, "[í˜ì˜¤ë„ ë¶„ì„] ì™„ë£Œ")
    unload_hate_model()
    return data

